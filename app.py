from flask import Flask, request, jsonify
from flask_cors import CORS
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain.prompts import PromptTemplate
import traceback
import re
import os

# Initialize Flask app
app = Flask(__name__)
CORS(app)  # Enable Cross-Origin Resource Sharing (CORS)

# Prompt template for generating scenario-based questions
scenario_prompt_template = PromptTemplate(
    input_variables=["profession"],
    template="""
    You are a professional scenario designer. Generate 2 scenario-based questions for a {profession}. Each scenario should present a practical situation requiring critical thinking and problem-solving skills relevant to the profession. 
    
    Please format the scenarios as follows:
    **Scenario 1:**
    [Describe the scenario]
    
    Question: [Ask a question related to the scenario]
    
    **Scenario 2:**
    [Describe the scenario]
    
    Question: [Ask a question related to the scenario]
    """
)

# Temporary storage to hold scenarios and answers before evaluation
scenario_storage = {}

@app.route('/generate_scenarios', methods=['POST'])
def generate_scenarios_api():
    try:
        # Extract input data from the request
        data = request.get_json()
        name = data.get('name')
        profession = data.get('profession')
        google_api_key = data.get('google_api_key')

        # Check if required parameters are provided
        if not name or not profession or not google_api_key:
            return jsonify({"error": "Missing 'name', 'profession', or 'google_api_key' in the request."}), 400

        # Initialize the LLM with the provided API key
        llm = ChatGoogleGenerativeAI(model="gemini-1.5-pro", verbose=False, temperature=0.5, google_api_key=google_api_key)

        # Generate scenarios using the AI model
        scenarios_prompt = scenario_prompt_template.format(profession=profession)
        response = llm.invoke(input=scenarios_prompt)

        if not hasattr(response, "content"):
            raise ValueError("Unexpected response format from the language model")

        # Print the generated content by Gemini in the terminal
        print("Generated Scenarios by Gemini:\n", response.content.strip())

        # Parse the generated scenarios with improved logic
        scenarios = parse_scenarios(response.content)

        # Store the scenarios temporarily
        scenario_storage[name] = {
            "scenarios": scenarios,
            "profession": profession,
            "llm": llm  # Store the LLM instance
        }

        # Construct the JSON response
        result = {
            "name": name,
            "profession": profession,
            "scenarios": scenarios,
            "answer_prompt": "Please provide your answers for the scenarios."
        }

        return jsonify(result)

    except Exception as e:
        # Capture error in JSON format
        error_result = {
            "error": {
                "message": str(e),
                "traceback": traceback.format_exc()
            }
        }
        return jsonify(error_result), 500

def parse_scenarios(scenarios_text):
    """
    Parses the text generated by the AI model to extract scenarios and their corresponding questions.
    """
    scenarios = []
    # Split the text into different scenario blocks using the scenario pattern
    scenario_blocks = re.split(r'\*\*Scenario \d+:\*\*', scenarios_text)

    # Remove any empty entries from the split result
    scenario_blocks = [block.strip() for block in scenario_blocks if block.strip()]

    # Iterate over each scenario block to extract the scenario and question
    for block in scenario_blocks:
        scenario = {"scenario": "", "question": ""}
        # Split the scenario block into scenario description and question
        parts = re.split(r'Question:', block, flags=re.IGNORECASE)
        
        # Assign the scenario and question to the dictionary
        scenario["scenario"] = parts[0].strip() if len(parts) > 0 else ""
        scenario["question"] = parts[1].strip() if len(parts) > 1 else ""

        scenarios.append(scenario)

    return scenarios

def parse_evaluation(evaluation_text):
    """
    Parses the evaluation text to separate the Analysis, Strengths, Areas for Improvement, and Overall Assessment.
    """
    # Use regular expressions to find each section
    analysis_match = re.search(r'## Analysis:\s*(.*?)\s*(?=## Strengths:|## Areas for Improvement:|## Overall Assessment:|$)', evaluation_text, re.DOTALL)
    strengths_match = re.search(r'## Strengths:\s*(.*?)\s*(?=## Areas for Improvement:|## Overall Assessment:|$)', evaluation_text, re.DOTALL)
    areas_for_improvement_match = re.search(r'## Areas for Improvement:\s*(.*?)\s*(?=## Overall Assessment:|$)', evaluation_text, re.DOTALL)
    overall_assessment_match = re.search(r'## Overall Assessment:\s*(.*)', evaluation_text, re.DOTALL)

    # Extract the content for each section, or provide default empty text
    return {
        "analysis": analysis_match.group(1).strip() if analysis_match else "",
        "strengths": strengths_match.group(1).strip() if strengths_match else "",
        "areas_for_improvement": areas_for_improvement_match.group(1).strip() if areas_for_improvement_match else "",
        "overall_assessment": overall_assessment_match.group(1).strip() if overall_assessment_match else ""
    }

@app.route('/submit_scenario_answers', methods=['POST'])
def submit_scenario_answers_api():
    try:
        # Extract input data from the request
        data = request.get_json()
        name = data.get('name')
        google_api_key = data.get('google_api_key')
        answers = data.get('answers')

        # Check if required parameters are provided
        if not name or not google_api_key or not answers:
            return jsonify({"error": "Missing 'name', 'google_api_key', or 'answers' in the request."}), 400

        # Retrieve the generated scenarios from temporary storage
        if name not in scenario_storage:
            return jsonify({"error": "No scenarios found for the provided name. Please generate scenarios first."}), 400

        # Retrieve necessary data from storage
        scenarios = scenario_storage[name]["scenarios"]
        profession = scenario_storage[name]["profession"]

        # Initialize the LLM with the provided API key
        llm = ChatGoogleGenerativeAI(model="gemini-1.5-pro", verbose=False, temperature=0.5, google_api_key=google_api_key)

        # Convert answers to a list to maintain order
        answers_list = [answers.get("q1", ""), answers.get("q2", "")]

        # Evaluate the answers using the AI model
        evaluation = evaluate_scenario_answers(llm, profession, scenarios, answers_list)

        # Print the evaluation generated by Gemini in the terminal
        print("Generated Evaluation by Gemini:\n", evaluation)

        # Parse the evaluation into different fields
        parsed_evaluation = parse_evaluation(evaluation)

        # Construct the final JSON response
        result = {
            "name": name,
            "profession": profession,
            "answers": answers,
            "evaluation_prompt": "Evaluating answers... This may take a moment.",
            "evaluation": parsed_evaluation
        }

        # Remove the scenarios data from storage after evaluation
        del scenario_storage[name]

        return jsonify(result)

    except Exception as e:
        # Capture error in JSON format
        error_result = {
            "error": {
                "message": str(e),
                "traceback": traceback.format_exc()
            }
        }
        return jsonify(error_result), 500

def evaluate_scenario_answers(llm, profession, scenarios, answers):
    result_prompt = f"""
    Analyze the following scenario-based responses for a {profession}:

    Scenario 1: {scenarios[0]['scenario']}
    Question: {scenarios[0]['question']}
    Answer: {answers[0]}

    Scenario 2: {scenarios[1]['scenario']}
    Question: {scenarios[1]['question']}
    Answer: {answers[1]}

    Please provide a brief analysis of the responses, considering the following:
    1. Critical thinking and problem-solving skills demonstrated
    2. Application of professional knowledge
    3. Areas of strength
    4. Areas for improvement

    Format the result as follows:
    ## Analysis:
    [Your analysis here]

    ## Strengths:
    - [Strength 1]
    - [Strength 2]

    ## Areas for Improvement:
    - [Area 1]
    - [Area 2]

    ## Overall Assessment:
    [Brief overall assessment]
    """

    response = llm.invoke(input=result_prompt)
    if hasattr(response, "content"):
        evaluation_text = response.content.strip()
    else:
        evaluation_text = "Error generating evaluation"

    return evaluation_text

if __name__ == "__main__":
    # Use environment variables for host and port or set default values
    host = os.getenv('FLASK_HOST', '0.0.0.0')
    port = int(os.getenv('FLASK_PORT', 5000))
    app.run(host=host, port=port, debug=True)
